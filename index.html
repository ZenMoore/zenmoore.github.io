<!DOCTYPE HTML>
<!--
	Strata by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Zekun "Moore" Wang</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<link rel="icon" href="images/avatar.png" type="image/x-icon" />
		<link rel="shortcut icon" href="images/avatar.png" type="image/x-icon" />
	</head>
	<body class="is-preload">

		<!-- Header -->
			<header id="header">
				<div class="inner">
					<a href="https://zenmoore.github.io" class="image avatar"><img src="images/avatar.png" alt="" /></a>
					<h1><strong>Zekun "Moore" Wang</strong></h1>
					<h3>NLP, LLM, MLLM, AGI.<br />Seeking 25Fall PhD/Job.</h3>
					<!-- ÁõÆÂΩï -->
					<nav id="nav">
						<ul>
							<li><a href="#about">About Me</a></li>
							<li><a href="#news">News</a></li>
							<li><a href="#pubs">Publications</a></li>
							<li><a href="#contact">Contact</a></li>
						</ul>
					</nav>
				</div>
			</header>

		<!-- Main -->
			<div id="main">

				<section id="about">
					<header class="major">
						<h2>About Me</h2>
					</header>
					<p>
					Welcome! My name is Zekun Moore Wang (Chinese: ÁéãÊ≥ΩÂù§; French: WANG Noah). 
					</p>
					<!-- I am a 2nd-year Graduate Student at Beihang University in √âcole Centrale de P√©kin (Sino-French Engineering School), advised by <a href="https://www.semanticscholar.org/author/Ke-Xu/145389711">Prof. Ke Xu</a>. 
					I am also a remote research assistant at ETH Z√ºrich, working with <a href="https://michaelzhouwang.github.io/">Wangchunshu Zhou</a> and <a href="https://scholar.google.com/citations?user=Tpp9ZjoAAAAJ&hl=en">Prof. Mrinmaya Sachan</a>. 
					Additionally, I contribute as a research intern at <a href="https://01.ai/">01.AI</a> & HKUST, working with <a href="https://scholar.google.com/citations?user=OdE3MsQAAAAJ&hl=en">Dr. Wenhao Huang</a> and <a href="https://bigaidream.github.io/">Dr. Jie Fu</a>.
					<br /><br />
					My primary research goal is to extend language models to the interactive world scope <a href="https://arxiv.org/pdf/2004.10151">[1]</a>, which I also term InteractiveNLP <a href="https://arxiv.org/abs/2305.13246">[2]</a>. 
					The interactivity of LLMs encompasses several dimensions: enhancing user experiences in Human-LM Interaction, their embodiment in the real or virtual environment (Env-LM Interaction), the emergence of an LLM society <a href="https://www.camel-ai.org/">[3]</a> (LM-LM Interaction), among others (e.g., KB-LM Interaction, Tool-LM Interaction).
					<br /><br />
					To achieve this goal, it involves efforts in two directions: 
					(1) <i>pre-tech</i>: Foundation Models, and (2) <i>post-tech</i>: InteractiveNLP. 
					In (1), I focus on building (pre-training) novel LLMs (esp., Multimodal LLMs) and constructing instruction tuning data <a href="https://arxiv.org/abs/2304.07987">[4]</a>. 
					In (2), I am interested in Role-Playing LLM <a href="https://arxiv.org/abs/2310.00746">[5]</a>, Alignment <a href="https://arxiv.org/abs/2312.15907">[6]</a>, Chain of Thought, Retrieval Augmentation, and Agents <a href="https://arxiv.org/abs/2402.12326">[7]</a>.
					<br /><br /> -->
					<p>
						I have a strong interest in all topics about LLMs and am actively exploring and expanding the boundaries of current LLM technology. My efforts are primarily focused on two directions: (1) Pre-Tech: Foundation Model, and (2) Post-Tech: Interactive NLP [<a href="https://arxiv.org/abs/2305.13246" target="_blank">1</a>].
					</p>
					<p>
						In the Foundation Model direction, I have extensive experience with LLMs and multimodal LLMs, particularly in <u>pre-training</u> <u>(w/ 100+ GPUs)</u> [<a href="https://zenmoore.notion.site/MIO-under-review-962eb81fbcf84fb5914a7548f48d8ea6?pvs=4" target="_blank">2</a>, <a href="https://arxiv.org/abs/2405.19327" target="_blank">3</a>], SFT [<a href="https://arxiv.org/abs/2310.00746" target="_blank">4</a>], alignment [<a href="https://zenmoore.notion.site/PopAlign-under-review-8512f5ec355b4ddbbdfe14717be0ab7c?pvs=4" target="_blank">5</a>, <a href="https://arxiv.org/abs/2312.15907" target="_blank">6</a>], data curation [<a href="https://arxiv.org/abs/2406.13923" target="_blank">7</a>, <a href="https://arxiv.org/abs/2304.07987" target="_blank">8</a>, <a href="https://arxiv.org/abs/2403.18058" target="_blank">9</a>], and evaluation [<a href="https://arxiv.org/abs/2310.00746" target="_blank">4</a>, <a href="https://arxiv.org/abs/2406.17588" target="_blank">10</a>, <a href="https://arxiv.org/abs/2401.11944" target="_blank">11</a>, <a href="https://arxiv.org/abs/2406.05862" target="_blank">12</a>, <a href="https://arxiv.org/abs/2406.07436" target="_blank">13</a>, <a href="https://arxiv.org/abs/2402.13109" target="_blank">14</a>]. For example, I led the development of <u>a GPT-4o-like MLLM</u> [<a href="https://zenmoore.notion.site/MIO-under-review-962eb81fbcf84fb5914a7548f48d8ea6?pvs=4" target="_blank">2</a>], led the <u>first</u> bilingual role-playing LLM [<a href="https://arxiv.org/abs/2310.00746" target="_blank">4</a>], and participated in the development of the well-known, <u>high-performing LLM</u>, MAP-Neo [<a href="https://arxiv.org/abs/2405.19327" target="_blank">3</a>]. I also have experience with <u>code LLMs</u> [<a href="https://arxiv.org/abs/2406.07436" target="_blank">13</a>], <u>long-context LLMs</u> [<a href="https://arxiv.org/abs/2406.17588" target="_blank">10</a>], among others.
					</p>
					<p>
						In the Interactive NLP direction, I am exploring various technical issues such as <u>RAG</u> [<a href="https://arxiv.org/abs/2310.00746" target="_blank">4</a>, <a href="https://arxiv.org/abs/2312.15907" target="_blank">6</a>], <u>agents</u> [<a href="https://arxiv.org/abs/2402.12326" target="_blank">15</a>, <a href="https://zenmoore.notion.site/RoleAgent-under-review-bd48c2ec3346430aa4d9b83a019b0ba0?pvs=4" target="_blank">16</a>], chain of thoughts [<a href="https://arxiv.org/abs/2310.00746" target="_blank">4</a>, <a href="https://zenmoore.notion.site/PopAlign-under-review-8512f5ec355b4ddbbdfe14717be0ab7c?pvs=4" target="_blank">5</a>], <u>alignment</u> [<a href="https://zenmoore.notion.site/PopAlign-under-review-8512f5ec355b4ddbbdfe14717be0ab7c?pvs=4" target="_blank">5</a>, <a href="https://arxiv.org/abs/2312.15907" target="_blank">6</a>, <a href="https://arxiv.org/abs/2405.19327" target="_blank">3</a>], and controllable text generation [<a href="https://zenmoore.notion.site/PositionID-under-review-dcc5120a2b3e47c0a24179d12e8aea78?pvs=4" target="_blank">17</a>].
					</p>
					<p>
						As of July 1, 2024, my Google Scholar profile includes <u>17 of my papers</u> with <u>134 citations</u>. Among them, 3 papers have been accepted by <u>ACL</u> and 1 by <u>Springer Nature</u>, while 5 and 4 papers are under review at <u>NeurIPS</u> and <u>EMNLP</u>, respectively.
					</p>
					<p>
						Moreover, I will spend some time on the research of AI For Social Good [<a href="https://arxiv.org/abs/2402.12326" target="_blank">15</a>], and I hope these AI technologies are truly useful.
					</p>
					<ul class="actions">
						<li><a href="https://drive.google.com/file/d/1nEkBsgITMZxnFVhszkG_IVyWQxy-Dkxx/view?usp=sharing" class="button">CV (June 2024)</a></li>
						<li><a href="https://scholar.google.com/citations?user=g-AOtlYAAAAJ&hl=en&oi=ao" class="button">Google Scholar</a></li>
					</ul>
				</section>

				<section id="news">
					<header class="major">
						<h2>News</h2>
					</header>
					<div class="news-items">
						<!-- Newest news item -->
						<!-- <div class="news-item">
							<p>[2024.02] Published the paper "<a href="https://arxiv.org/abs/2402.12326">PsychoGAT</a>".</p>
						</div> -->
						<!-- <div class="news-item">
							<p>[2024.01] Published the paper "<a href="https://arxiv.org/abs/2401.11944">CMMMU</a>" (posted by AK).</p>
						</div>
						<div class="news-item">
							<p>[2023.12] Published the paper "<a href="https://arxiv.org/abs/2312.15907">OPO</a>" (posted by Êú∫Âô®‰πãÂøÉ).</p>
						</div> -->
						
						<div class="news-item">
							<p>[2024.05] üçª Got 3 papers accepted to ACL 2024 + Findings (<a href="https://arxiv.org/abs/2310.00746">RoleLLM</a>, <a href="https://arxiv.org/abs/2402.12326">PsychoGAT</a>, and <a href="https://arxiv.org/abs/2402.13109">CIF-Bench</a>). Thanks to all my collaborators! See you in Bangkok, Thailand!</p>
						</div>
						<div class="news-item">
							<p>[2024.02] üë®‚Äçüéì Start my remote research internship at ETH Zurich, advised by <a href="https://michaelzhouwang.github.io/">Wangchunshu Zhou</a> and <a href="https://scholar.google.com/citations?user=Tpp9ZjoAAAAJ\&hl=en">Prof. Mrinmaya Sachan</a>.</p>
						</div>
						<div class="news-item">
							<p>[2023.10] üì∞ Published the paper "<a href="https://arxiv.org/abs/2310.00746">RoleLLM</a>" (posted by Aran Komatsuzaki).</p>
						</div>
						<div class="news-item">
							<p>[2023.08] üë®‚Äçüíª Start my research internship at <a href="https://01.ai/">01.AI</a> & HKUST, advised by <a href="https://scholar.google.com/citations?user=OdE3MsQAAAAJ&hl=en">Dr. Wenhao Huang</a> and <a href="https://bigaidream.github.io/">Dr. Jie Fu</a>.</p>
						</div>
						<div class="news-item">
							<p>[2023.05] üì∞ Published the paper "<a href="https://arxiv.org/abs/2305.13246">InteractiveNLP</a>" (posted by Êú∫Âô®‰πãÂøÉ).</p>
						</div>
						<!-- <div class="news-item">
							<p>[2023.04] Published the paper "<a href="https://arxiv.org/abs/2304.07987">COIG</a>" (posted by AK).</p>
						</div> -->
						<div class="news-item special-event">
							<p>- [2022.11] ü§Ø ChatGPT's release. A new era of LLMs began!</p>
						</div>
						<div class="news-item">
							<p>[2022.08] üë®‚Äçüéì Start my Master study at Beihang University & √âcole Centrale, advised by <a href="https://www.semanticscholar.org/author/Ke-Xu/145389711">Prof. Ke Xu</a>.</p>
						</div>
						<div class="news-item">
							<p>[2022.06] üë®‚Äçüéì Got my bachelor's degree in Beihang University & √âcole Centrale.</p>
						</div>
						<div class="news-item">
							<p>[2022.04] üë®‚Äçüíª Start my research internship at <a href="https://www.baai.ac.cn/english.html">BAAI</a>, advised by <a href="https://bigaidream.github.io/">Dr. Jie Fu</a>.</p>
						</div>
						<div class="news-item">
							<p>[2021.09] üë®‚Äçüíª Start my R&D internship at <a href="https://www.langboat.com/en">Langboat</a>, advised by <a href="https://www.semanticscholar.org/author/Mingtong-Liu/51173986">Dr. Mingtong Liu</a> and <a href="https://scholar.google.co.jp/citations?user=a0w5c0gAAAAJ&hl=en">Dr. Ming Zhou</a>.</p>
						</div>
						<!-- Older news items -->
					</div>
				</section>
				
				<section id="pubs">
					<header class="major">
						<h2>Selected Publications & Preprints</h2>
					</header>
					<div class="row">
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://zenmoore.notion.site/MIO-under-review-962eb81fbcf84fb5914a7548f48d8ea6?pvs=4" class="image fit thumb">
								<img src="images/fulls/mio.png" alt="MIO Image" />
							</a>
							<h3>MIO: A Foundation Model on Multimodal Tokens</h3>
							<p>- <u>Zekun Wang</u>, Kang Zhu, Chunpu Xu, Wangchunshu Zhou, Jiaheng Liu, Yibo Zhang, Jiashuo Wang, Ning Shi, Ge Zhang, Siyu Li, Yizhi Li, Yuanxing Zhang, Ke Xu, Wenhao Huang, Jie Fu</p>
							<p>- Under review (coming soon)</p>
							<p>- A foundation model capable of understanding and generating speech, texts, images, and videos in an end-to-end and autoregressive manner. The model undergoes pre-training and SFT with 100+ GPUs.</p>
							<p>[<a href="https://zenmoore.notion.site/MIO-under-review-962eb81fbcf84fb5914a7548f48d8ea6?pvs=4">preview</a>]</p>
						</article>
						
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2310.00746" class="image fit thumb">
								<img src="images/fulls/rolellm-framework.png" alt="RoleLLM Image" />
							</a>
							<h3>RoleLLM: Benchmarking, Eliciting, and Enhancing Role-Playing Abilities of Large Language Models</h3>
							<p>- <u>Zekun Moore Wang</u>*, Zhongyuan Peng*, Haoran Que*, Jiaheng Liu, Wangchunshu Zhou, Yuhan Wu, Hongcheng Guo, Ruitong Gan, Zehao Ni, Jian Yang, Man Zhang, Zhaoxiang Zhang, Wanli Ouyang, Ke Xu, Stephen W. Huang, Jie Fu, Junran Peng</p>
							<p>- <u>ACL 2024 Findings</u> (posted by <a href="https://twitter.com/arankomatsuzaki/status/1709037788417437758">Aran Komatsuzaki</a>)</p>
							<p>- We introduce RoleLLM, a role-playing framework of data construction and evaluation (RoleBench), as well as solutions for both closed-source and open-source models (RoleGPT, RoleLLaMA, RoleGLM). We also propose Context-Instruct for long-text knowledge extraction and role-specific knowledge injection.</p>
							<p><a href="https://arxiv.org/abs/2310.00746">[paper]</a> <a href="https://github.com/InteractiveNLP-Team/RoleLLM-public">[github]</a> <a href="https://huggingface.co/datasets/ZenMoore/RoleBench">[data]</a> <a href="https://github.com/open-compass/opencompass/pull/633">[opencompass]</a> <a href="https://twitter.com/arankomatsuzaki/status/1709037788417437758">[Aran Komatsuzaki]</a> <a href="https://www.bilibili.com/video/BV1VH4y1B7Er">[talk]</a></p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2305.13246" class="image fit thumb">
								<img src="images/fulls/interactivenlp.png" alt="InteractiveNLP Image" />
							</a>
							<h3>Interactive Natural Language Processing</h3>
							<p>- <u>Zekun Wang</u>*, Ge Zhang*, Kexin Yang, Ning Shi, Wangchunshu Zhou, Shaochun Hao, Guangzheng Xiong, Yizhi Li, Mong Yuan Sim, Xiuying Chen, Qingqing Zhu, Zhenzhu Yang, Adam Nik, Qi Liu, Chenghua Lin, Shi Wang, Ruibo Liu, Wenhu Chen, Ke Xu, Dayiheng Liu, Yike Guo, Jie Fu</p>
							<p>- <u>Springer Nature</u> (editing) (posted by <a href="https://mp.weixin.qq.com/s/qNKM_xyYJigSGtE4J3UXXQ">Êú∫Âô®‰πãÂøÉ</a>)</p>
							<p>- A survey on the next-generation LLM technology (100 pages), which covers the topics of Alignment, Tool-Use, KB, RAG, Agents, CoT, Embodied AI, Memory, SFT, etc.</p>
							<p>[<a href="https://arxiv.org/abs/2305.13246">paper</a>] [<a href="https://github.com/InteractiveNLP-Team/awesome-InteractiveNLP-papers">github</a>] [<a href="https://mp.weixin.qq.com/s/qNKM_xyYJigSGtE4J3UXXQ">Êú∫Âô®‰πãÂøÉ</a>] [<a href="https://www.techbeat.net/talk-info?id=791">talk</a>]</p>
						</article>
						
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://zenmoore.notion.site/PopAlign-under-review-8512f5ec355b4ddbbdfe14717be0ab7c?pvs=4" class="image fit thumb">
								<img src="images/fulls/popalign.png" alt="PopAlign Image" />
							</a>
							<h3>PopAlign: Prompt-Model-Pipeline Contrast for LLM Alignment through Comprehensive Contrastive Distillation</h3>
							<p>- <u>Zekun Moore Wang</u>, Wangchunshu Zhou, Shenzhi Wang, Kang Zhu, Jiaheng Liu, Ke Xu, Jie Fu, Wenhao Huang, Mrinmaya Sachan</p>
							<p>- Under review (coming soon) </p>
							<p>- We propose PopAlign, a novel framework for contrastive distillation by contrasting prompts, models, and pipelines. Our Elicitive Contrast approach can significantly improve the alignment performance.</p>
							<p>[<a href="https://zenmoore.notion.site/PopAlign-under-review-8512f5ec355b4ddbbdfe14717be0ab7c?pvs=4">preview</a>]</p>
						</article>
						
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2402.12326" class="image fit thumb">
								<img src="images/fulls/psychogat.png" alt="PsychoGAT Image" />
							</a>
							<h3>PsychoGAT: A Novel Psychological Measurement Paradigm through Interactive Fiction Games with LLM Agents</h3>
							<p>- Qisen Yang*, <u>Zekun Wang</u>*, Honghui Chen, Shenzhi Wang, Yifan Pu, Xin Gao, Wenhao Huang, Shiji Song, Gao Huang</p>
							<p>- <u>ACL 2024 Main</u> (posted by <a href="https://mp.weixin.qq.com/s/U24GF1UIHm0I-mj7UgdYsw">ÈáèÂ≠ê‰Ωç</a>)</p>
							<p>- A LLM agent for psychological assessment. This agent can generate extra-long texts as an interactive game under the control of psychometric questionnaires and user interaction.</p>
							<p><a href="https://arxiv.org/abs/2402.12326">[paper]</a> <a href="https://x.com/ZenMoore1/status/1760593023824695509?s=20">[twitter]</a> <a href="https://mp.weixin.qq.com/s/U24GF1UIHm0I-mj7UgdYsw">[ÈáèÂ≠ê‰Ωç]</a></p>
						</article>
						
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2406.07436" class="image fit thumb">
								<img src="images/fulls/mceval.png" alt="McEval Image" />
							</a>
							<h3>McEval: Massively Multilingual Code Evaluation</h3>
							<p>- Linzhen Chai*, Shukai Liu*, Jian Yang*, Yuwei Yin, Ke Jin, Jiaheng Liu, Tao Sun, Ge Zhang, Changyu Ren, Hongcheng Guo, <u>Zekun Wang</u>, Boyang Wang, Xianjie Wu, Bing Wang, Tongliang Li, Liqun Yang, Sufeng Duan, Zhoujun Li</p>
							<p>- Under review, 2024</p>
							<p>- To facilitate the development of code LLMs, we introduce a complete framework that includes the multilingual code instruction corpora, multilingual coder LLM (mCoder), and multilingual code evaluation benchmark.</p>
							<p>[<a href="https://arxiv.org/abs/2406.07436">paper</a>]</p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2405.19327" class="image fit thumb">
								<img src="images/fulls/map-neo.png" alt="MAP-Neo Image" />
							</a>
							<h3>MAP-Neo: Highly Capable and Transparent Bilingual Large Language Model Series</h3>
							<p>- Ge Zhang, Scott Qu, Jiaheng Liu, Chenchen Zhang, Chenghua Lin, Chou Leuang Yu, Danny Pan, Esther Cheng, Jie Liu, Qunshu Lin, Raven Yuan, Tuney Zheng, Wei Pang, Xinrun Du, Yiming Liang, Yinghao Ma, Yizhi Li, Ziyang Ma, Bill Lin, Emmanouil Benetos, Huan Yang, Junting Zhou, Kaijing Ma, Minghao Liu, Morry Niu, <u>Noah Wang</u>, Quehry Que, Ruibo Liu, Sine Liu, Shawn Guo, Soren Gao, Wangchunshu Zhou, Xinyue Zhang, Yizhi Zhou, Yubo Wang, Yuelin Bai, Yuhan Zhang, Yuxiang Zhang, Zenith Wang, Zhenzhu Yang, Zijian Zhao, Jiajun Zhang, Wanli Ouyang, Wenhao Huang, Wenhu Chen</p>
							<p>- Technical Report, 2024</p>
							<p>- A fully transparent and open-source generalist LLM with industry-level performance.</p>
							<p><a href="https://arxiv.org/abs/2405.19327">[paper]</a> <a href="https://huggingface.co/papers?date=2024-05-30">[daily papers]</a></p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2406.17588" class="image fit thumb">
								<img src="images/fulls/longins.png" alt="LongIns Image" />
							</a>
							<h3>LongIns: A Challenging Long-context Instruction-based Exam for LLMs</h3>
							<p>- Shawn Gavin, Tuney Zheng, Jiaheng Liu, Quehry Que, <u>Noah Wang</u>, Jian Yang, Chenchen Zhang, Wenhao Huang, Wenhu Chen, Ge Zhang</p>
							<p>- Under review, 2024</p>
							<p>- A benchmark for evaluating long-context LLMs through instruction-based exams.</p>
							<p><a href="https://arxiv.org/abs/2406.17588">[paper]</a> <a href="https://huggingface.co/papers?date=2024-06-26">[daily papers]</a></p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2401.11944" class="image fit thumb"><img src="images/fulls/cmmmu.png" alt="CMMMU Image" /></a>
							<h3>CMMMU: A Chinese Massive Multi-discipline Multimodal Understanding Benchmark</h3>
							<p>- Ge Zhang*, Xinrun Du*, Bei Chen*, Yiming Liang, Tongxu Luo, Tianyu Zheng, Kang Zhu, Yuyang Cheng, Chunpu Xu, Shuyue Guo, Haoran Zhang, Xingwei Qu, Junjie Wang, Ruibin Yuan, Yizhi Li, <u>Zekun Wang</u>, Yudong Liu, Yu-Hsuan Tsai, Fengji Zhang, Chenghua Lin, Wenhao Huang, Wenhu Chen, Jie Fu</p>
							<p>- Under review, 2024 (posted by <a href="https://mp.weixin.qq.com/s/dbLfc6TR0sunAPtWXAChCA">Êú∫Âô®‰πãÂøÉ</a>)</p>
							<p>- A Chinese massive multi-discipline multimodal understanding benchmark.</p>
							<p><a href="https://arxiv.org/abs/2401.11944">[paper]</a> <a href="https://mp.weixin.qq.com/s/dbLfc6TR0sunAPtWXAChCA">[Êú∫Âô®‰πãÂøÉ]</a> <a href="https://huggingface.co/datasets/m-a-p/CMMMU">[dataset]</a> <a href="https://github.com/CMMMU-Benchmark/CMMMU">[github]</a> <a href="https://x.com/_akhaliq/status/1749635037945823723?s=20">[AK]</a></p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2406.13923" class="image fit thumb">
								<img src="images/fulls/pin.png" alt="PIN Image" />
							</a>
							<h3>PIN: A Knowledge-Intensive Dataset for Paired and Interleaved Multimodal Documents</h3>
							<p>- Junjie Wang, Yin Zhang, Yatai Ji, Yuxiang Zhang, Chunyang Jiang, Yubo Wang, Kang Zhu, <u>Zekun Wang</u>, Tiezhen Wang, Wenhao Huang, Jie Fu, Bei Chen, Qunshu Lin, Minghao Liu, Ge Zhang, Wenhu Chen</p>
							<p>- Under review, 2024</p>
							<p>- We introduce a new multimodal dataset, PIN-14M, for Paired and Interleaved multimodal documents. It supports training of knowledge-intensive MLLMs with enhanced OCR abilities.</p>
							<p><a href="https://arxiv.org/abs/2406.13923">[paper]</a></p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://zenmoore.notion.site/PositionID-under-review-dcc5120a2b3e47c0a24179d12e8aea78?pvs=4" class="image fit thumb">
								<img src="images/fulls/positionid.png" alt="PositionID Image" />
							</a>
							<h3>PositionID: LLMs can Control Lengths, Copy and Paste with Explicit Positional Awareness</h3>
							<p>- <u>Zekun Wang</u>, Feiyu Duan, Yibo Zhang, Wangchunshu Zhou, Ke Xu, Wenhao Huang, Jie Fu</p>
							<p>- Under review (coming soon)</p>
							<p>- We propose methods for enhancing the LLMs' abilities in length control and copy-paste tool-use.</p>
							<p><a href="https://zenmoore.notion.site/PositionID-under-review-dcc5120a2b3e47c0a24179d12e8aea78?pvs=4">[preview]</a></p>
						</article>
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2406.05862" class="image fit thumb">
								<img src="images/fulls/ii-bench.png" alt="II-Bench Image" />
							</a>
							<h3>II-Bench: An Image Implication Understanding Benchmark for Multimodal Large Language Models</h3>
							<p>- Ziqiang Liu, Feiteng Fang, Xi Feng, Xinrun Du, Chenhao Zhang, <u>Zekun Wang</u>, Yuelin Bai, Qixuan Zhao, Liyang Fan, Chengguang Gan, Hongquan Lin, Jiaming Li, Yuansheng Ni, Haihong Wu, Yaswanth Narsupalli, Zhigang Zheng, Chengming Li, Xiping Hu, Ruifeng Xu, Xiaojun Chen, Min Yang, Jiaheng Liu, Ruibo Liu, Wenhao Huang, Ge Zhang, Shiwen Ni</p>
							<p>- Under review, 2024</p>
							<p>- We propose the Image Implication Understanding Benchmark, II-Bench, which aims to evaluate the model's higher-order perception of images.</p>
							<p><a href="https://arxiv.org/abs/2406.05862">[paper]</a></p>
						</article>
						
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2302.02066" class="image fit thumb">
								<img src="images/fulls/cif-bench.png" alt="CIF-Bench Image" />
							</a>
							<h3>CIF-Bench: A Chinese Instruction-Following Benchmark for Evaluating the Generalizability of Large Language Models</h3>
							<p>- Yizhi Li, Ge Zhang, Xingwei Qu, Jiali Li, Zhaoqun Li, <u>Zekun Wang</u>, Hao Li, Ruibin Yuan, Yinghao Ma, Kai Zhang, Wangchunshu Zhou, Yiming Liang, Lei Zhang, Lei Ma, Jiajun Zhang, Zuowen Li, Stephen W. Huang, Chenghua Lin, Wenhu Chen, Jie Fu</p>
							<p>- <u>ACL 2024 Findings</u></p>
							<p>- Designed to evaluate the zero-shot generalizability of LLMs to the Chinese language.</p>
							<p><a href="https://arxiv.org/abs/2302.02066">[paper]</a></p>
						</article>						
						<article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2312.15907" class="image fit thumb"><img src="images/fulls/opo.png" alt="OPO Image" /></a>
							<h3>Align on the Fly: Adapting Chatbot Behavior to Established Norms</h3>
							<p>- Chunpu Xu, Steffi Chern, Ethan Chern, Ge Zhang, <u>Zekun Wang</u>, Ruibo Liu, Jing Li, Jie Fu, Pengfei Liu</p>
							<p>- Under review, 2024 (posted by <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650905254&idx=5&sn=27193d02ec48bd304c658baf99de90fb&chksm=84e45ed8b393d7ceb8df07b3b89634ce19cb04abb61333ea1d6392e366ecb24990a6b7a63e86&mpshare=1&scene=2&srcid=0123MnWHsaRQTJxkNu6ZhYvO&sharer_shareinfo=77461c83893ced2a4bc97a622a39f6d7&sharer_shareinfo_first=743558285d671c876be1bed5e1db5ebb#rd">Êú∫Âô®‰πãÂøÉ</a>)</p>
							<p>- A novel method that dynamically aligns LLMs with human values.</p>
							<p><a href="https://arxiv.org/abs/2312.15907">[paper]</a> <a href="https://mp.weixin.qq.com/s?__biz=MzA3MzI4MjgzMw==&mid=2650905254&idx=5&sn=27193d02ec48bd304c658baf99de90fb&chksm=84e45ed8b393d7ceb8df07b3b89634ce19cb04abb61333ea1d6392e366ecb24990a6b7a63e86&mpshare=1&scene=2&srcid=0123MnWHsaRQTJxkNu6ZhYvO&sharer_shareinfo=77461c83893ced2a4bc97a622a39f6d7&sharer_shareinfo_first=743558285d671c876be1bed5e1db5ebb#rd">[Êú∫Âô®‰πãÂøÉ]</a></p>
						</article>
						<!-- <article class="col-6 col-12-xsmall work-item">
							<a href="https://arxiv.org/abs/2304.07987" class="image fit thumb"><img src="images/fulls/coig.png" alt="COIG Image" /></a>
							<h3>Chinese open instruction generalist: A preliminary release</h3>
							<p>- Ge Zhang*, Yemin Shi*, Ruibo Liu, Ruibin Yuan, Yizhi Li, Siwei Dong, Yu Shu, Zhaoqun Li, <u>Zekun Wang</u>, Chenghua Lin, Wenhao Huang, Jie Fu</p>
							<p>- arXiv, 2023</p>
							<p>- An instruction tuning dataset for Chinese Foundation Models.</p>
							<p><a href="https://arxiv.org/abs/2304.07987">[paper]</a> <a href="https://huggingface.co/datasets/BAAI/COIG">[data]</a> <a href="https://twitter.com/_akhaliq/status/1648144986477666304">[AK]</a></p>
						</article> -->
					</div>
					<ul class="actions">
						<li><a href="https://scholar.google.com/citations?user=g-AOtlYAAAAJ&hl=en&oi=ao" class="button">Full List</a></li>
					</ul>
				</section>
				
				<!-- <section id="blogs">
				</section> -->
				<!-- <section id="life">
				</section> -->

				<section id="contact">
					<h2>Get In Touch</h2>
					<p>&#x1F525;I am looking for (1) 2025 Fall PhD or Job Position, (2) Collaborators, (3) Co-founders for a Research Community, and (4) INTJ Friends! <br />
						&#x1F917;Feel free to contact me.&#x1F447;</p>
					<div class="row">
						<div class="col-8 col-12-small">
							<form method="post" action="https://formspree.io/f/xpzgvkdd">
								<div class="row gtr-uniform gtr-50">
									<div class="col-6 col-12-xsmall"><input type="text" name="name" id="name" placeholder="Your Name" /></div>
									<div class="col-6 col-12-xsmall"><input type="email" name="email" id="email" placeholder="Your Email" /></div>
									<div class="col-12"><textarea name="message" id="message" placeholder="Message" rows="4"></textarea></div>
									<!-- Submit button inside the form -->
									<div class="col-12">
										<ul class="actions">
											<li><input type="submit" value="Send Message" /></li>
										</ul>
									</div>
								</div>
							</form>
						</div>							
						<div class="col-4 col-12-small">
							<ul class="labeled-icons">
								<li>
									<h3 class="icon solid fa-home"><span class="label">Address</span></h3>
									<!-- Dayun Village Student Apartments<br /> -->
									<!-- 29 Zhichun Rd.<br />
									Haidian District, <br /> -->
									Beijing, China
								</li>
								<li>
									<h3 class="icon solid fa-mobile-alt"><span class="label">Phone</span></h3>
									+86 180 0349 7833
								</li>
								<li>
									<h3 class="icon solid fa-envelope"><span class="label">Email</span></h3>
									<a href="mailto:zenmoore@buaa.edu.cn">zenmoore@buaa.edu.cn</a>
								</li>
								<li>
									<h3 class="icon"><i class="fab fa-weixin"></i><span class="label">WeChat</span></h3>
									zen1057398161
								</li>
								<li>
									<h3 class="icon"><i class="fab fa-twitter"></i><span class="label">Twitter</span></h3>
									<a href="https://twitter.com/ZenMoore1">ZenMoore1</a>
								</li>
							</ul>
						</div>
					</div>
				</section>

				<!-- <script type="text/javascript" id="mapmyvisitors" src="//mapmyvisitors.com/map.js?d=9Uc-vnt_HdUKfGMBskVAP3JWlm8x6PeDfWgiSXm4Jes&cl=ffffff&w=a"></script> -->
				<a href='https://mapmyvisitors.com/web/1bvme'  title='Visit tracker'><img src='https://mapmyvisitors.com/map.png?cl=6e2f6a&w=1000&t=n&d=9Uc-vnt_HdUKfGMBskVAP3JWlm8x6PeDfWgiSXm4Jes&co=ffffff&ct=000000'/></a>
				<!-- <a href="https://mapmyvisitors.com/web/1bvme" title="Visit tracker">
					<img src="https://mapmyvisitors.com/map.png?d=9Uc-vnt_HdUKfGMBskVAP3JWlm8x6PeDfWgiSXm4Jes&cl=ffffff" 
						 width="1000" 
						 height="auto" 
						 style="max-width:100%;height:auto;" />
				</a> -->
	

			</div>
						

				<!-- Four -->
				<!--
					<section id="four">
						<h2>Elements</h2>

						<section>
							<h4>Text</h4>
							<p>This is <b>bold</b> and this is <strong>strong</strong>. This is <i>italic</i> and this is <em>emphasized</em>.
							This is <sup>superscript</sup> text and this is <sub>subscript</sub> text.
							This is <u>underlined</u> and this is code: <code>for (;;) { ... }</code>. Finally, <a href="#">this is a link</a>.</p>
							<hr />
							<header>
								<h4>Heading with a Subtitle</h4>
								<p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
							</header>
							<p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
							<header>
								<h5>Heading with a Subtitle</h5>
								<p>Lorem ipsum dolor sit amet nullam id egestas urna aliquam</p>
							</header>
							<p>Nunc lacinia ante nunc ac lobortis. Interdum adipiscing gravida odio porttitor sem non mi integer non faucibus ornare mi ut ante amet placerat aliquet. Volutpat eu sed ante lacinia sapien lorem accumsan varius montes viverra nibh in adipiscing blandit tempus accumsan.</p>
							<hr />
							<h2>Heading Level 2</h2>
							<h3>Heading Level 3</h3>
							<h4>Heading Level 4</h4>
							<h5>Heading Level 5</h5>
							<h6>Heading Level 6</h6>
							<hr />
							<h5>Blockquote</h5>
							<blockquote>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan faucibus. Vestibulum ante ipsum primis in faucibus lorem ipsum dolor sit amet nullam adipiscing eu felis.</blockquote>
							<h5>Preformatted</h5>
							<pre><code>i = 0;

while (!deck.isInOrder()) {
print 'Iteration ' + i;
deck.shuffle();
i++;
}

print 'It took ' + i + ' iterations to sort the deck.';</code></pre>
						</section>

						<section>
							<h4>Lists</h4>
							<div class="row">
								<div class="col-6 col-12-xsmall">
									<h5>Unordered</h5>
									<ul>
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Sagittis adipiscing lorem eleifend.</li>
										<li>Felis enim feugiat dolore viverra.</li>
									</ul>
									<h5>Alternate</h5>
									<ul class="alt">
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Sagittis adipiscing lorem eleifend.</li>
										<li>Felis enim feugiat dolore viverra.</li>
									</ul>
								</div>
								<div class="col-6 col-12-xsmall">
									<h5>Ordered</h5>
									<ol>
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Etiam vel felis at lorem sed viverra.</li>
										<li>Felis enim feugiat dolore viverra.</li>
										<li>Dolor pulvinar etiam magna etiam.</li>
										<li>Etiam vel felis at lorem sed viverra.</li>
										<li>Felis enim feugiat dolore viverra.</li>
									</ol>
									<h5>Icons</h5>
									<ul class="icons">
										<li><a href="#" class="icon brands fa-twitter"><span class="label">Twitter</span></a></li>
										<li><a href="#" class="icon brands fa-facebook-f"><span class="label">Facebook</span></a></li>
										<li><a href="#" class="icon brands fa-instagram"><span class="label">Instagram</span></a></li>
										<li><a href="#" class="icon brands fa-github"><span class="label">Github</span></a></li>
										<li><a href="#" class="icon brands fa-dribbble"><span class="label">Dribbble</span></a></li>
										<li><a href="#" class="icon brands fa-tumblr"><span class="label">Tumblr</span></a></li>
									</ul>
								</div>
							</div>
							<h5>Actions</h5>
							<ul class="actions">
								<li><a href="#" class="button primary">Default</a></li>
								<li><a href="#" class="button">Default</a></li>
							</ul>
							<ul class="actions small">
								<li><a href="#" class="button primary small">Small</a></li>
								<li><a href="#" class="button small">Small</a></li>
							</ul>
							<div class="row">
								<div class="col-6 col-12-small">
									<ul class="actions stacked">
										<li><a href="#" class="button primary">Default</a></li>
										<li><a href="#" class="button">Default</a></li>
									</ul>
								</div>
								<div class="col-6 col-12-small">
									<ul class="actions stacked">
										<li><a href="#" class="button primary small">Small</a></li>
										<li><a href="#" class="button small">Small</a></li>
									</ul>
								</div>
								<div class="col-6 col-12-small">
									<ul class="actions stacked">
										<li><a href="#" class="button primary fit">Default</a></li>
										<li><a href="#" class="button fit">Default</a></li>
									</ul>
								</div>
								<div class="col-6 col-12-small">
									<ul class="actions stacked">
										<li><a href="#" class="button primary small fit">Small</a></li>
										<li><a href="#" class="button small fit">Small</a></li>
									</ul>
								</div>
							</div>
						</section>

						<section>
							<h4>Table</h4>
							<h5>Default</h5>
							<div class="table-wrapper">
								<table>
									<thead>
										<tr>
											<th>Name</th>
											<th>Description</th>
											<th>Price</th>
										</tr>
									</thead>
									<tbody>
										<tr>
											<td>Item One</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Two</td>
											<td>Vis ac commodo adipiscing arcu aliquet.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Three</td>
											<td> Morbi faucibus arcu accumsan lorem.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Four</td>
											<td>Vitae integer tempus condimentum.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Five</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
									</tbody>
									<tfoot>
										<tr>
											<td colspan="2"></td>
											<td>100.00</td>
										</tr>
									</tfoot>
								</table>
							</div>

							<h5>Alternate</h5>
							<div class="table-wrapper">
								<table class="alt">
									<thead>
										<tr>
											<th>Name</th>
											<th>Description</th>
											<th>Price</th>
										</tr>
									</thead>
									<tbody>
										<tr>
											<td>Item One</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Two</td>
											<td>Vis ac commodo adipiscing arcu aliquet.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Three</td>
											<td> Morbi faucibus arcu accumsan lorem.</td>
											<td>29.99</td>
										</tr>
										<tr>
											<td>Item Four</td>
											<td>Vitae integer tempus condimentum.</td>
											<td>19.99</td>
										</tr>
										<tr>
											<td>Item Five</td>
											<td>Ante turpis integer aliquet porttitor.</td>
											<td>29.99</td>
										</tr>
									</tbody>
									<tfoot>
										<tr>
											<td colspan="2"></td>
											<td>100.00</td>
										</tr>
									</tfoot>
								</table>
							</div>
						</section>

						<section>
							<h4>Buttons</h4>
							<ul class="actions">
								<li><a href="#" class="button primary">Primary</a></li>
								<li><a href="#" class="button">Default</a></li>
							</ul>
							<ul class="actions">
								<li><a href="#" class="button large">Large</a></li>
								<li><a href="#" class="button">Default</a></li>
								<li><a href="#" class="button small">Small</a></li>
							</ul>
							<ul class="actions fit">
								<li><a href="#" class="button primary fit">Fit</a></li>
								<li><a href="#" class="button fit">Fit</a></li>
							</ul>
							<ul class="actions fit small">
								<li><a href="#" class="button primary fit small">Fit + Small</a></li>
								<li><a href="#" class="button fit small">Fit + Small</a></li>
							</ul>
							<ul class="actions">
								<li><a href="#" class="button primary icon solid fa-download">Icon</a></li>
								<li><a href="#" class="button icon solid fa-download">Icon</a></li>
							</ul>
							<ul class="actions">
								<li><span class="button primary disabled">Primary</span></li>
								<li><span class="button disabled">Default</span></li>
							</ul>
						</section>

						<section>
							<h4>Form</h4>
							<form method="post" action="#">
								<div class="row gtr-uniform gtr-50">
									<div class="col-6 col-12-xsmall">
										<input type="text" name="demo-name" id="demo-name" value="" placeholder="Name" />
									</div>
									<div class="col-6 col-12-xsmall">
										<input type="email" name="demo-email" id="demo-email" value="" placeholder="Email" />
									</div>
									<div class="col-12">
										<select name="demo-category" id="demo-category">
											<option value="">- Category -</option>
											<option value="1">Manufacturing</option>
											<option value="1">Shipping</option>
											<option value="1">Administration</option>
											<option value="1">Human Resources</option>
										</select>
									</div>
									<div class="col-4 col-12-small">
										<input type="radio" id="demo-priority-low" name="demo-priority" checked>
										<label for="demo-priority-low">Low Priority</label>
									</div>
									<div class="col-4 col-12-small">
										<input type="radio" id="demo-priority-normal" name="demo-priority">
										<label for="demo-priority-normal">Normal Priority</label>
									</div>
									<div class="col-4 col-12-small">
										<input type="radio" id="demo-priority-high" name="demo-priority">
										<label for="demo-priority-high">High Priority</label>
									</div>
									<div class="col-6 col-12-small">
										<input type="checkbox" id="demo-copy" name="demo-copy">
										<label for="demo-copy">Email me a copy of this message</label>
									</div>
									<div class="col-6 col-12-small">
										<input type="checkbox" id="demo-human" name="demo-human" checked>
										<label for="demo-human">I am a human and not a robot</label>
									</div>
									<div class="col-12">
										<textarea name="demo-message" id="demo-message" placeholder="Enter your message" rows="6"></textarea>
									</div>
									<div class="col-12">
										<ul class="actions">
											<li><input type="submit" value="Send Message" class="primary" /></li>
											<li><input type="reset" value="Reset" /></li>
										</ul>
									</div>
								</div>
							</form>
						</section>

						<section>
							<h4>Image</h4>
							<h5>Fit</h5>
							<div class="box alt">
								<div class="row gtr-50 gtr-uniform">
									<div class="col-12"><span class="image fit"><img src="images/fulls/05.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/01.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/02.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/03.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/04.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/05.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/06.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/03.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/02.jpg" alt="" /></span></div>
									<div class="col-4"><span class="image fit"><img src="images/thumbs/01.jpg" alt="" /></span></div>
								</div>
							</div>
							<h5>Left &amp; Right</h5>
							<p><span class="image left"><img src="images/avatar.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
							<p><span class="image right"><img src="images/avatar.jpg" alt="" /></span>Fringilla nisl. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent. Donec accumsan interdum nisi, quis tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent tincidunt felis sagittis eget. tempus euismod. Vestibulum ante ipsum primis in faucibus vestibulum. Blandit adipiscing eu felis iaculis volutpat ac adipiscing accumsan eu faucibus. Integer ac pellentesque praesent.</p>
						</section>

					</section>
				-->

		<!-- Footer -->
			<footer id="footer">
				<div class="inner">
					<ul class="icons">
						<li><a href="https://twitter.com/ZenMoore1" class="icon brands fa-twitter" title="Twitter"><span class="label">Twitter</span></a></li>
						<li><a href="https://github.com/ZenMoore" class="icon brands fa-github" title="Github"><span class="label">Github</span></a></li>
						<li><a href="mailto:zenmoore@buaa.edu.cn" class="icon solid fa-envelope" title="Email"><span class="label">Email</span></a></li>
						<li><a href="https://scholar.google.com/citations?user=g-AOtlYAAAAJ&hl=en&oi=ao" class="icon brands fa-google" title="Google Scholar"><span class="label">Google Scholar</span></a></li>
						<li><a href="https://drive.google.com/file/d/1nEkBsgITMZxnFVhszkG_IVyWQxy-Dkxx/view?usp=sharing" class="icon solid fa-file-pdf" title="CV"><span class="label">CV</span></a></li>
					</ul>					
					<!-- <ul class="copyright">
						<li>&copy; Zekun Wang</li><li>Designed with <a href="http://html5up.net">HTML5 UP</a></li>
					</ul> -->
				</div>
			</footer>

		<!-- Scripts -->
			<script src="assets/js/jquery.min.js"></script>
			<script src="assets/js/jquery.poptrox.min.js"></script>
			<script src="assets/js/browser.min.js"></script>
			<script src="assets/js/breakpoints.min.js"></script>
			<script src="assets/js/util.js"></script>
			<script src="assets/js/main.js"></script>

	</body>
</html>